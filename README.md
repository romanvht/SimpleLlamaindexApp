# Помощник базы знаний

Этот проект представляет собой простую реализацию интеллектуального помощника, построенного на основе технологии GPT и использующего библиотеку LlamaIndex для обработки и индексации документов. Приложение использует архитектуру RAG для ответов на вопросы пользователя на основе проиндексированных документов.

## Возможности

- Индексация документов из заданной директории
- API-сервер для обработки запросов пользователей
- Веб-интерфейс для взаимодействия с помощником

## Установка

1. Клонируйте репозиторий:
   ```
   git clone https://github.com/romanvht/SimpleLlamaindexApp.git
   cd SimpleLlamaindexApp
   ```

2. Установите необходимые зависимости:
   ```
   pip install -r requirements.txt
   ```

3. Создайте директорию `docs` и поместите в неё документы, которые нужно проиндексировать.

4. Замените `<ваш ключ ProxyAPI>` на ваш актуальный ключ API в файлах `start_bot.py` и `start_index.py`.

## Использование

### Индексация документов

Переместите нужные документы в дирректорию `docs`

Для индексации документов выполните:

```
python start_index.py
```

Это создаст индекс документов в директории `./storage`.

### Запуск API-сервера

Для запуска API-сервера выполните:

```
python start_bot.py
```

Сервер будет доступен по адресу `http://localhost:5000`.

### Использование веб-интерфейса

Откройте файл `index.html` в браузере для взаимодействия с помощником через веб-интерфейс.

## API

Сервер предоставляет единственную конечную точку:

- `POST /api`
  - Тело запроса: `{"query": "Ваш вопрос здесь"}`
  - Ответ: `{"status": "success", "response": "Ответ помощника"}`

## Зависимости

- Flask
- LlamaIndex
- OpenAI (через ProxyAPI)

## Примечания

- Проект использует модель GPT-4o-mini для генерации ответов.
- Для встраивания используется модель text-embedding-3-large.